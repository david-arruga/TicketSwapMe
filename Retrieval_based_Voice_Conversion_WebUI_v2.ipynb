{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oex6meCm9NOL"
      },
      "source": [
        "# [Retrieval-based-Voice-Conversion-WebUI](https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI) Training notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFFCx5J80SGa"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/RVC-Project/Retrieval-based-Voice-Conversion-WebUI/blob/main/Retrieval_based_Voice_Conversion_WebUI_v2.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GmFP6bN9dvOq",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# @title #查看显卡\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jwu07JgqoFON"
      },
      "outputs": [],
      "source": [
        "# @title 挂载谷歌云盘\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "# ============ PREP PYTHON 3.10 ============\n",
        "set -e\n",
        "curl -Ls https://micro.mamba.pm/api/micromamba/linux-64/latest \\\n",
        " | tar -xvj -C /usr/local/bin/ bin/micromamba --strip-components=1\n",
        "/usr/local/bin/micromamba create -y -n rvc -c conda-forge python=3.10\n",
        "\n",
        "cat >/usr/local/bin/pip310 <<'EOF'\n",
        "#!/bin/bash\n",
        "exec /usr/local/bin/micromamba run -n rvc python -m pip \"$@\"\n",
        "EOF\n",
        "chmod +x /usr/local/bin/pip310\n",
        "\n",
        "cat >/usr/local/bin/py310 <<'EOF'\n",
        "#!/bin/bash\n",
        "exec /usr/local/bin/micromamba run -n rvc python \"$@\"\n",
        "EOF\n",
        "chmod +x /usr/local/bin/py310\n",
        "\n",
        "/usr/local/bin/py310 - <<'PY'\n",
        "import platform\n",
        "print(\"Python:\", platform.python_version())\n",
        "PY\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "nRUwb2Jf9T50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wjddIFr1oS3W",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# @title #安装依赖\n",
        "!apt-get update -y\n",
        "!apt-get -y install build-essential python3-dev ffmpeg\n",
        "\n",
        "!pip310 install --upgrade setuptools wheel\n",
        "!pip310 install \"pip<24.1\"\n",
        "\n",
        "# Pre-requisitos que fairseq necesita con metadatos antiguos\n",
        "!pip310 install \"omegaconf==2.0.6\" \"hydra-core==1.0.7\" \"Cython<3\" \"setuptools<72\"\n",
        "\n",
        "# El resto tal y como marca la template, usando pip310\n",
        "!pip310 install faiss-cpu==1.7.2 fairseq==0.12.2 gradio==3.14.0 ffmpeg ffmpeg-python praat-parselmouth pyworld numpy==1.23.5 numba==0.56.4 librosa==0.9.2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ge_97mfpgqTm"
      },
      "outputs": [],
      "source": [
        "# @title #克隆仓库\n",
        "\n",
        "!mkdir Retrieval-based-Voice-Conversion-WebUI\n",
        "%cd /content/Retrieval-based-Voice-Conversion-WebUI\n",
        "!git init\n",
        "!git remote add origin https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI.git\n",
        "!git fetch origin cfd984812804ddc9247d65b14c82cd32e56c1133 --depth=1\n",
        "!git reset --hard FETCH_HEAD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BLDEZADkvlw1"
      },
      "outputs": [],
      "source": [
        "# @title #更新仓库（一般无需执行）\n",
        "!git pull"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pqE0PrnuRqI2",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# @title #安装aria2\n",
        "!apt -y install -qq aria2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UG3XpUwEomUz",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# @title 下载底模\n",
        "\n",
        "# v1\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained/D32k.pth -d /content/Retrieval-based-Voice-Conversion-WebUI/pretrained -o D32k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained/D40k.pth -d /content/Retrieval-based-Voice-Conversion-WebUI/pretrained -o D40k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained/D48k.pth -d /content/Retrieval-based-Voice-Conversion-WebUI/pretrained -o D48k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained/G32k.pth -d /content/Retrieval-based-Voice-Conversion-WebUI/pretrained -o G32k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained/G40k.pth -d /content/Retrieval-based-Voice-Conversion-WebUI/pretrained -o G40k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained/G48k.pth -d /content/Retrieval-based-Voice-Conversion-WebUI/pretrained -o G48k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained/f0D32k.pth -d /content/Retrieval-based-Voice-Conversion-WebUI/pretrained -o f0D32k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained/f0D40k.pth -d /content/Retrieval-based-Voice-Conversion-WebUI/pretrained -o f0D40k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained/f0D48k.pth -d /content/Retrieval-based-Voice-Conversion-WebUI/pretrained -o f0D48k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained/f0G32k.pth -d /content/Retrieval-based-Voice-Conversion-WebUI/pretrained -o f0G32k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained/f0G40k.pth -d /content/Retrieval-based-Voice-Conversion-WebUI/pretrained -o f0G40k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained/f0G48k.pth -d /content/Retrieval-based-Voice-Conversion-WebUI/pretrained -o f0G48k.pth\n",
        "\n",
        "# v2\n",
        "# !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained_v2/D32k.pth -d /content/Retrieval-based-Voice-Conversion-WebUI/pretrained_v2 -o D32k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained_v2/D40k.pth -d /content/Retrieval-based-Voice-Conversion-WebUI/pretrained_v2 -o D40k.pth\n",
        "# !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained_v2/D48k.pth -d /content/Retrieval-based-Voice-Conversion-WebUI/pretrained_v2 -o D48k.pth\n",
        "# !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained_v2/G32k.pth -d /content/Retrieval-based-Voice-Conversion-WebUI/pretrained_v2 -o G32k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained_v2/G40k.pth -d /content/Retrieval-based-Voice-Conversion-WebUI/pretrained_v2 -o G40k.pth\n",
        "# !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained_v2/G48k.pth -d /content/Retrieval-based-Voice-Conversion-WebUI/pretrained_v2 -o G48k.pth\n",
        "# !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained_v2/f0D32k.pth -d /content/Retrieval-based-Voice-Conversion-WebUI/pretrained_v2 -o f0D32k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained_v2/f0D40k.pth -d /content/Retrieval-based-Voice-Conversion-WebUI/pretrained_v2 -o f0D40k.pth\n",
        "# !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained_v2/f0D48k.pth -d /content/Retrieval-based-Voice-Conversion-WebUI/pretrained_v2 -o f0D48k.pth\n",
        "# !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained_v2/f0G32k.pth -d /content/Retrieval-based-Voice-Conversion-WebUI/pretrained_v2 -o f0G32k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained_v2/f0G40k.pth -d /content/Retrieval-based-Voice-Conversion-WebUI/pretrained_v2 -o f0G40k.pth\n",
        "# !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained_v2/f0G48k.pth -d /content/Retrieval-based-Voice-Conversion-WebUI/pretrained_v2 -o f0G48k.pth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HugjmZqZRuiF",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# @title #下载人声分离模型\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/uvr5_weights/HP2-人声vocals+非人声instrumentals.pth -d /content/Retrieval-based-Voice-Conversion-WebUI/uvr5_weights -o HP2-人声vocals+非人声instrumentals.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/uvr5_weights/HP5-主旋律人声vocals+其他instrumentals.pth -d /content/Retrieval-based-Voice-Conversion-WebUI/uvr5_weights -o HP5-主旋律人声vocals+其他instrumentals.pth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2RCaT9FTR0ej",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# @title #下载hubert_base\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/hubert_base.pt -d /content/Retrieval-based-Voice-Conversion-WebUI -o hubert_base.pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "GM4TVpTD9NOS"
      },
      "outputs": [],
      "source": [
        "# @title #下载rmvpe模型\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/rmvpe.pt -d /content/Retrieval-based-Voice-Conversion-WebUI -o rmvpe.pt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# De OPUS a WAV procesado"
      ],
      "metadata": {
        "id": "c6R1NrcSrm5I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# OPUS -> WAV (mono, PCM16) con 3 MODOS: no_trim | soft_trim | vad\n",
        "# === CONFIGURA AQUÍ ===\n",
        "SRC  = \"/content/drive/MyDrive/RAVC/fabiandataset\"           # .opus\n",
        "DST  = \"/content/drive/MyDrive/RAVC/fabiandataset40k_clean\"  # salida final\n",
        "SR   = 40000                                                 # 48000 si quieres 48k\n",
        "MODE = \"no_trim\"                                             # \"no_trim\" | \"soft_trim\" | \"vad\"\n",
        "\n",
        "import os, glob, shlex, subprocess, sys, math\n",
        "os.makedirs(DST, exist_ok=True)\n",
        "\n",
        "def run(cmd):\n",
        "    return subprocess.run(cmd, shell=True).returncode == 0\n",
        "\n",
        "def ff(cmd_list):\n",
        "    return subprocess.run(cmd_list, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "\n",
        "# ——— helpers VAD (solo si MODE==\"vad\") ———\n",
        "def vad_cut_to_wav(inp, out, sr=SR, aggressiveness=2):\n",
        "    \"\"\"\n",
        "    Recorte por voz con webrtcvad: genera WAV temporal PCM16, trocea por voz y pega.\n",
        "    Más robusto que silenceremove.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        import webrtcvad, wave, contextlib, collections, struct\n",
        "        import tempfile, numpy as np\n",
        "\n",
        "        # 1) decodifica a wav mono/sr fijo\n",
        "        with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as tmpwav:\n",
        "            tmp = tmpwav.name\n",
        "        if not run(f'ffmpeg -nostdin -hide_banner -loglevel error -y -i {shlex.quote(inp)} -ac 1 -ar {sr} -sample_fmt s16 {shlex.quote(tmp)}'):\n",
        "            return False\n",
        "\n",
        "        # 2) lee frames y aplica VAD\n",
        "        vad = webrtcvad.Vad(aggressiveness)\n",
        "        frame_dur_ms = 30\n",
        "        bytes_per_sample = 2\n",
        "        frame_len = int(sr * frame_dur_ms / 1000) * bytes_per_sample\n",
        "        with contextlib.closing(wave.open(tmp, 'rb')) as wf:\n",
        "            assert wf.getnchannels() == 1 and wf.getsampwidth() == 2 and wf.getframerate() == sr\n",
        "            pcm = wf.readframes(wf.getnframes())\n",
        "\n",
        "        # trocear en frames\n",
        "        frames = [pcm[i:i+frame_len] for i in range(0, len(pcm), frame_len)]\n",
        "        voiced = [vad.is_speech(f, sr) if len(f)==frame_len else False for f in frames]\n",
        "\n",
        "        # 3) agrupa regiones con voz\n",
        "        chunks = []\n",
        "        cur = []\n",
        "        for i, (f,isv) in enumerate(zip(frames, voiced)):\n",
        "            if isv:\n",
        "                cur.append(f)\n",
        "            else:\n",
        "                if cur:\n",
        "                    chunks.append(b\"\".join(cur)); cur=[]\n",
        "        if cur:\n",
        "            chunks.append(b\"\".join(cur))\n",
        "\n",
        "        # si no hay voz, exporta 0.5s de silencio para no perder el archivo\n",
        "        if not chunks:\n",
        "            import numpy as np\n",
        "            silence = (np.zeros(int(sr*0.5)).astype(np.int16)).tobytes()\n",
        "            chunks = [silence]\n",
        "\n",
        "        # 4) combina y escribe WAV temporal\n",
        "        payload = b\"\".join(chunks)\n",
        "        with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as tmpcut:\n",
        "            out_cut = tmpcut.name\n",
        "        with wave.open(out_cut, 'wb') as wf:\n",
        "            wf.setnchannels(1); wf.setsampwidth(2); wf.setframerate(sr)\n",
        "            wf.writeframes(payload)\n",
        "\n",
        "        # 5) normaliza y escribe a destino final\n",
        "        af = f\"loudnorm=I=-20:LRA=7:TP=-1.5\"\n",
        "        ok = run(f'ffmpeg -nostdin -hide_banner -loglevel error -y -i {shlex.quote(out_cut)} -af {shlex.quote(af)} -ac 1 -ar {sr} -sample_fmt s16 {shlex.quote(out)}')\n",
        "        try: os.remove(tmp)\n",
        "        except: pass\n",
        "        try: os.remove(out_cut)\n",
        "        except: pass\n",
        "        return ok\n",
        "    except Exception as e:\n",
        "        return False\n",
        "\n",
        "# ——— procesamiento ———\n",
        "patterns = [\"**/*.opus\",\"**/*.OPUS\"]\n",
        "paths = []\n",
        "for pat in patterns:\n",
        "    paths.extend(glob.glob(os.path.join(SRC, pat), recursive=True))\n",
        "print(\"Encontrados .opus:\", len(paths))\n",
        "ok, fail = 0, 0\n",
        "\n",
        "for p in paths:\n",
        "    rel   = os.path.relpath(p, SRC)\n",
        "    base  = os.path.splitext(rel)[0]\n",
        "    out_dir = os.path.join(DST, os.path.dirname(rel)); os.makedirs(out_dir, exist_ok=True)\n",
        "    out = os.path.join(out_dir, base + \".wav\")\n",
        "\n",
        "    if MODE == \"no_trim\":\n",
        "        # SOLO normaliza, no toca duración\n",
        "        af = \"loudnorm=I=-20:LRA=7:TP=-1.5\"\n",
        "        cmd = f'ffmpeg -nostdin -hide_banner -loglevel error -y -i {shlex.quote(p)} -af {shlex.quote(af)} -ac 1 -ar {SR} -sample_fmt s16 {shlex.quote(out)}'\n",
        "        ok += run(cmd); fail += (not ok or 0) and 0\n",
        "\n",
        "    elif MODE == \"soft_trim\":\n",
        "        # Recorte ULTRA conservador (+ normalización)\n",
        "        # Umbral muy bajo (-50 dB) + exige 1.0 s de silencio para cortar\n",
        "        af = (\n",
        "          \"silenceremove=\"\n",
        "          \"start_periods=1:start_silence=1.0:start_threshold=-50dB:\"\n",
        "          \"stop_periods=1:stop_silence=1.0:stop_threshold=-50dB,\"\n",
        "          \"loudnorm=I=-20:LRA=7:TP=-1.5\"\n",
        "        )\n",
        "        cmd = f'ffmpeg -nostdin -hide_banner -loglevel error -y -i {shlex.quote(p)} -af {shlex.quote(af)} -ac 1 -ar {SR} -sample_fmt s16 {shlex.quote(out)}'\n",
        "        ok += run(cmd); fail += (not ok or 0) and 0\n",
        "\n",
        "    elif MODE == \"vad\":\n",
        "        # Recorta por voz con WebRTC VAD + normaliza\n",
        "        if not vad_cut_to_wav(p, out, sr=SR, aggressiveness=2):\n",
        "            fail += 1\n",
        "        else:\n",
        "            ok += 1\n",
        "    else:\n",
        "        print(f\"❌ MODE inválido: {MODE}\"); break\n",
        "\n",
        "print(f\"Terminado. OK={ok} | Fail={len(paths)-ok} | Salida={DST}\")\n"
      ],
      "metadata": {
        "id": "xr4AoplHrqZq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== AUDITORÍA EN CONSOLA: OPUS vs WAV (sin CSV) =====\n",
        "SRC = \"/content/drive/MyDrive/RAVC/fabiandataset\"           # .opus originales\n",
        "DST = \"/content/drive/MyDrive/RAVC/fabiandataset40k_clean\"  # .wav generados (no_trim)\n",
        "\n",
        "import os, glob, subprocess, math, statistics\n",
        "\n",
        "def ffprobe_duration(path: str):\n",
        "    try:\n",
        "        out = subprocess.check_output(\n",
        "            [\"ffprobe\",\"-v\",\"error\",\n",
        "             \"-show_entries\",\"format=duration\",\n",
        "             \"-of\",\"default=noprint_wrappers=1:nokey=1\",\n",
        "             path],\n",
        "            stderr=subprocess.STDOUT, text=True\n",
        "        ).strip()\n",
        "        return float(out) if out and out != \"N/A\" else None\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "def key_rel(path, root):  # relativa sin extensión\n",
        "    return os.path.splitext(os.path.relpath(path, root))[0]\n",
        "\n",
        "def fmt_hms(sec):\n",
        "    if sec is None or not (isinstance(sec,(int,float)) and math.isfinite(sec)): return \"N/A\"\n",
        "    sec = int(round(sec)); h = sec//3600; m = (sec%3600)//60; s = sec%60\n",
        "    return f\"{h:02d}:{m:02d}:{s:02d}\"\n",
        "\n",
        "# Recolecta OPUS\n",
        "opus = []\n",
        "for pat in (\"**/*.opus\",\"**/*.OPUS\"): opus += glob.glob(os.path.join(SRC, pat), recursive=True)\n",
        "if not opus:\n",
        "    print(f\"❌ No se encontraron .opus en: {SRC}\")\n",
        "else:\n",
        "    rows = []\n",
        "    for op in opus:\n",
        "        key = key_rel(op, SRC)\n",
        "        wav = os.path.join(DST, key + \".wav\")\n",
        "        src_sec = ffprobe_duration(op)\n",
        "        if not os.path.exists(wav):\n",
        "            rows.append({\"key\":key,\"src_sec\":src_sec,\"dst_sec\":None,\"ratio\":None,\"status\":\"missing_wav\"})\n",
        "            continue\n",
        "        dst_sec = ffprobe_duration(wav)\n",
        "        ratio = (dst_sec/src_sec) if (src_sec and dst_sec and src_sec>0) else None\n",
        "        rows.append({\"key\":key,\"src_sec\":src_sec,\"dst_sec\":dst_sec,\"ratio\":ratio,\"status\":\"ok\" if ratio is not None else \"bad_meta\"})\n",
        "\n",
        "    total = len(rows)\n",
        "    ok = sum(1 for r in rows if r[\"status\"]==\"ok\")\n",
        "    miss = sum(1 for r in rows if r[\"status\"]==\"missing_wav\")\n",
        "    bad = sum(1 for r in rows if r[\"status\"]==\"bad_meta\")\n",
        "    ratios = [r[\"ratio\"] for r in rows if r[\"ratio\"] is not None]\n",
        "    total_src = sum((r[\"src_sec\"] or 0) for r in rows)\n",
        "    total_dst = sum((r[\"dst_sec\"] or 0) for r in rows)\n",
        "    mean_ratio = statistics.fmean(ratios) if ratios else None\n",
        "    median_ratio = statistics.median(ratios) if ratios else None\n",
        "\n",
        "    b_lt02 = sum(1 for r in ratios if r < 0.2)\n",
        "    b_02_05 = sum(1 for r in ratios if 0.2 <= r < 0.5)\n",
        "    b_05_08 = sum(1 for r in ratios if 0.5 <= r < 0.8)\n",
        "    b_ge08 = sum(1 for r in ratios if r >= 0.8)\n",
        "\n",
        "    worst = sorted((r for r in rows if r[\"ratio\"] is not None), key=lambda x: x[\"ratio\"])[:5]\n",
        "    good  = sorted((r for r in rows if r.get(\"ratio\") and r[\"ratio\"]>=0.95), key=lambda x: -x[\"ratio\"])[:5]\n",
        "\n",
        "    print(\"========== AUDITORÍA OPUS→WAV ==========\")\n",
        "    print(f\"Archivos .opus          : {len(opus)}\")\n",
        "    print(f\"Pairs medidos (ok)      : {ok}\")\n",
        "    print(f\"WAV faltantes           : {miss}\")\n",
        "    print(f\"Metadatos inválidos     : {bad}\")\n",
        "    print(f\"Duración total OPUS     : {fmt_hms(total_src)} ({total_src/3600:.2f} h)\")\n",
        "    print(f\"Duración total WAV      : {fmt_hms(total_dst)} ({total_dst/3600:.2f} h)\")\n",
        "    print(f\"Ratio medio dst/src     : {mean_ratio:.3f}\" if mean_ratio is not None else \"Ratio medio dst/src : N/A\")\n",
        "    print(f\"Ratio mediano dst/src   : {median_ratio:.3f}\" if median_ratio is not None else \"Ratio mediano dst/src: N/A\")\n",
        "\n",
        "    print(\"\\nBuckets ratio dst/src:\")\n",
        "    print(f\"  <0.20     : {b_lt02}\")\n",
        "    print(f\"  0.20–0.50 : {b_02_05}\")\n",
        "    print(f\"  0.50–0.80 : {b_05_08}\")\n",
        "    print(f\"  ≥0.80     : {b_ge08}\")\n",
        "\n",
        "    print(\"\\n-- Peores 5 ratios (recorte/sesgo más alto) --\")\n",
        "    for r in worst:\n",
        "        print(f\"ratio={r['ratio']:.3f} | src={fmt_hms(r['src_sec'])} -> dst={fmt_hms(r['dst_sec'])} | {r['key']}\")\n",
        "\n",
        "    if good:\n",
        "        print(\"\\n-- Ejemplos buenos (ratio≥0.95) --\")\n",
        "        for r in good:\n",
        "            print(f\"ratio={r['ratio']:.3f} | src={fmt_hms(r['src_sec'])} -> dst={fmt_hms(r['dst_sec'])} | {r['key']}\")\n",
        "\n",
        "    if b_02_05 + b_lt02 > 0:\n",
        "        print(\"\\n⚠️  Hay recortes fuertes. Usa conversion **sin trim** o **soft_trim/vad**.\")\n",
        "    else:\n",
        "        print(\"\\n✅ Sin recortes groseros detectados.\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "v5cLL1B4sRcl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========= 1) VERIFICAR CARPETA EN DRIVE (Bash) =========\n",
        "%%bash\n",
        "set -e\n",
        "ls -lah \"/content/drive/MyDrive/RAVC/wavsfiltrados\" | head -n 20 || {\n",
        "  echo \"❌ No existe: /content/drive/MyDrive/RAVC/wavsfiltrados\"; exit 1; }"
      ],
      "metadata": {
        "collapsed": true,
        "id": "KQzsJMetB5jw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========== 1) VERIFICAR CARPETA EN DRIVE (Bash) ==========\n",
        "%%bash\n",
        "set -e\n",
        "ls -lah \"/content/drive/MyDrive/RAVC/fabiandataset40k_clean\" | head -n 20 || {\n",
        "  echo \"❌ No existe: /content/drive/MyDrive/RAVC/fabiandataset40k_clean\"; exit 1; }\n"
      ],
      "metadata": {
        "id": "VRjibxBPs48s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========= 2) CREAR ZIP EN DRIVE (Bash) =========\n",
        "%%bash\n",
        "set -e\n",
        "mkdir -p \"/content/drive/MyDrive/dataset\"\n",
        "# comprimimos la carpeta completa a un zip dentro de 'dataset'\n",
        "cd \"/content/drive/MyDrive\"\n",
        "zip -r -9 -q \"dataset/midataset_wavsfiltrados.zip\" \"RAVC/wavsfiltrados\"\n",
        "# mostrar tamaño del zip resultante\n",
        "ls -lh \"/content/drive/MyDrive/dataset/midataset_wavsfiltrados.zip\""
      ],
      "metadata": {
        "id": "hP6TZyJ3CCh-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========== 2) CREAR ZIP EN DRIVE (Bash) ==========\n",
        "%%bash\n",
        "set -e\n",
        "mkdir -p \"/content/drive/MyDrive/dataset\"\n",
        "cd \"/content/drive/MyDrive\"\n",
        "# Comprime preservando la ruta relativa RAVC/fabiandataset40k_clean dentro del zip\n",
        "zip -r -9 -q \"dataset/fabian40k_clean.zip\" \"RAVC/fabiandataset40k_clean\"\n",
        "echo \"✅ ZIP creado:\"\n",
        "ls -lh \"/content/drive/MyDrive/dataset/fabian40k_clean.zip\"\n"
      ],
      "metadata": {
        "id": "BZraGxxws7dx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mwk7Q0Loqzjx",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# @title 从谷歌云盘加载打包好的数据集到/content/dataset\n",
        "DATASET = \"/content/drive/MyDrive/dataset/midataset_wavsfiltrados.zip\"  # <-- TU ZIP\n",
        "\n",
        "!mkdir -p /content/dataset\n",
        "!unzip -o -d /content/dataset -B \"{DATASET}\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========== 3) CARGAR ZIP A /content/dataset (Python) ==========\n",
        "DATASET = \"/content/drive/MyDrive/dataset/fabian40k_clean.zip\"  # <-- TU ZIP\n",
        "\n",
        "!mkdir -p /content/dataset\n",
        "# Descomprime preservando RAVC/fabiandataset40k_clean\n",
        "!unzip -o -d /content/dataset -B {DATASET}\n",
        "\n",
        "# Comprobación rápida del destino esperado:\n",
        "!ls -lah \"/content/dataset/RAVC/fabiandataset40k_clean\" | head -n 20\n"
      ],
      "metadata": {
        "id": "0RUgvIcgs-H0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PDlFxWHWEynD",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# @title #重命名数据集中的重名文件  (RENOMBRAR DUPLICADOS)\n",
        "# Lista tu carpeta real\n",
        "!ls -a \"/content/dataset/RAVC/wavsfiltrados\"\n",
        "\n",
        "# Instala 'rename' si no está, y renombra archivos tipo \"nombre.ext~N\" -> \"nombre_N.ext\"\n",
        "!apt-get update -y >/dev/null 2>&1 && apt-get install -y rename >/dev/null 2>&1\n",
        "!rename 's/(\\w+)\\.(\\w+)~(\\d*)/$1_$3.$2/' /content/dataset/RAVC/wavsfiltrados/*.*~* || true\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========== 4) RENOMBRAR DUPLICADOS Y LISTAR (Python) ==========\n",
        "# Instala 'rename' si no está, y renombra archivos tipo \"nombre.ext~N\" -> \"nombre_N.ext\"\n",
        "!apt-get update -y >/dev/null 2>&1 && apt-get install -y rename >/dev/null 2>&1\n",
        "!rename 's/(\\w+)\\.(\\w+)~(\\d*)/$1_$3.$2/' /content/dataset/RAVC/fabiandataset40k_clean/*.*~* || true\n",
        "\n",
        "# Lista final (muestra primeras 30 entradas)\n",
        "!ls -lah \"/content/dataset/RAVC/fabiandataset40k_clean\" | sed -n '1,30p'\n"
      ],
      "metadata": {
        "id": "-Ra3NzEYtBk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instalar torchaudio\n"
      ],
      "metadata": {
        "id": "BCZIMtAbqppC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Desinstala lo que haya en py310 (por si acaso)\n",
        "!pip310 uninstall -y torch torchaudio\n",
        "\n",
        "# Instala torch==2.5.1 y torchaudio==2.5.1 para CUDA 12.1 (compatible con tu driver CUDA 12.x)\n",
        "!pip310 install --index-url https://download.pytorch.org/whl/cu121 torch==2.5.1+cu121 torchaudio==2.5.1+cu121\n",
        "\n",
        "# Verifica que es en py310 y con las versiones correctas\n",
        "!py310 - <<'PY'\n",
        "import platform, torch, torchaudio\n",
        "print(\"Python:\", platform.python_version())\n",
        "print(\"torch:\", torch.__version__, \"| cuda:\", torch.version.cuda)\n",
        "print(\"torchaudio:\", torchaudio.__version__)\n",
        "PY\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "EVbzlyHAKoK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!py310 -c \"import platform, torch, torchaudio; print('Python:', platform.python_version()); print('torch:', torch.__version__, '| cuda:', torch.version.cuda); print('torchaudio:', torchaudio.__version__)\"\n"
      ],
      "metadata": {
        "id": "OpzDpRggLf4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instalar tensorboard"
      ],
      "metadata": {
        "id": "7nkRqfQBqwnT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalar en el entorno correcto (py310)\n",
        "!pip310 install -q tensorboard tensorboardX\n",
        "\n",
        "# Verificación rápida\n",
        "!py310 -c \"import tensorboard, torch; print('tensorboard OK | torch', torch.__version__)\"\n",
        "\n",
        "# (opcional) comprobar que el índice existe\n",
        "!test -f /content/Retrieval-based-Voice-Conversion-WebUI/logs/primer-test/added.index && echo 'index OK' || echo 'falta index'\n"
      ],
      "metadata": {
        "id": "W0sQN6UmN9sl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instalar matplot"
      ],
      "metadata": {
        "id": "ivUigGYbq2ce"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instala versión compatible en el entorno correcto\n",
        "!pip310 install -q \"matplotlib<3.9\"\n",
        "\n",
        "# Verifica\n",
        "!py310 -c \"import matplotlib; print('matplotlib', matplotlib.__version__)\"\n"
      ],
      "metadata": {
        "id": "p_BvpG-uSsO5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# WEBUI"
      ],
      "metadata": {
        "id": "QoybJKuwKo3G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7vh6vphDwO0b",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "%cd /content/Retrieval-based-Voice-Conversion-WebUI\n",
        "!env MPLBACKEND=Agg py310 infer-web.py --colab --pycmd py310 --port 7865 --noautoopen\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "EXP=\"fabian-test\"   # <-- usa el nombre exacto de tu experimento\n",
        "BASE=\"/content/Retrieval-based-Voice-Conversion-WebUI/logs/$EXP\"\n",
        "echo \"=== Índices FAISS ===\"\n",
        "ls -lh \"$BASE\"/*.index 2>/dev/null || echo \"⏳ Aún no hay .index\"\n"
      ],
      "metadata": {
        "id": "nNLO4nGfB0Wh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "EXP=\"fabian-test\"\n",
        "BASE=\"/content/Retrieval-based-Voice-Conversion-WebUI/logs/$EXP\"\n",
        "\n",
        "echo \"=== ARCHIVOS DEL EXPERIMENTO ===\"\n",
        "ls -lh \"$BASE\" || { echo \"❌ No existe $BASE\"; exit 1; }\n",
        "\n",
        "echo \"=== ÍNDICES FAISS ===\"\n",
        "ls -lh \"$BASE\"/*.index 2>/dev/null || echo \"⏳ Aún no hay .index\"\n",
        "\n",
        "echo \"=== FEATURES DISCRETAS ===\"\n",
        "ls -lh \"$BASE/3_feature256\" | sed -n '1,15p' || true\n",
        "\n",
        "echo \"=== ESPACIO DISCO ===\"\n",
        "df -h | sed -n '1,5p'\n"
      ],
      "metadata": {
        "id": "hEgUFj09ClYZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EXP = \"fabian-test\"\n",
        "base = f\"/content/Retrieval-based-Voice-Conversion-WebUI/logs/{EXP}\"\n",
        "\n",
        "import os, glob, numpy as np, re, math\n",
        "\n",
        "# total_fea.npy si existe (consolidado)\n",
        "p_total = os.path.join(base, \"total_fea.npy\")\n",
        "if os.path.exists(p_total):\n",
        "    X = np.load(p_total, mmap_mode=\"r\")\n",
        "    n_total = X.shape[0]\n",
        "    dim = X.shape[1]\n",
        "    print(\"total_fea.npy:\", X.shape, \"| aprox MB:\", X.nbytes/1e6)\n",
        "else:\n",
        "    # suma de todos los .npy en 3_feature256\n",
        "    files = sorted(glob.glob(os.path.join(base, \"3_feature256\", \"*.npy\")))\n",
        "    n_total = 0\n",
        "    dim = None\n",
        "    for i,f in enumerate(files[:10]):  # mira 10 para inferir dim\n",
        "        arr = np.load(f, mmap_mode=\"r\")\n",
        "        n_total += arr.shape[0]\n",
        "        dim = arr.shape[1] if dim is None else dim\n",
        "    # estimación para todos\n",
        "    if len(files) > 10:\n",
        "        # estima con la media de los 10 primeros\n",
        "        avg = n_total/10\n",
        "        n_total = int(avg*len(files))\n",
        "    print(f\"3_feature256: ficheros={len(files)} | estimación vectores={n_total} | dim≈{dim}\")\n",
        "\n",
        "# extrae nlist del nombre del índice entrenado\n",
        "idxs = sorted(glob.glob(os.path.join(base, \"trained_IVF*_v1.index\")))\n",
        "if idxs:\n",
        "    m = re.search(r\"IVF(\\d+)_\", os.path.basename(idxs[0]))\n",
        "    nlist = int(m.group(1)) if m else None\n",
        "    print(\"trained index:\", os.path.basename(idxs[0]), \"| nlist:\", nlist)\n",
        "    if nlist and n_total:\n",
        "        print(f\"N/nlist ≈ {n_total}/{nlist} ≈ {n_total/max(1,nlist):.1f} vectores por lista\")\n",
        "else:\n",
        "    print(\"⚠️ No se encontró trained_IVF...index (raro si antes lo viste).\")\n"
      ],
      "metadata": {
        "id": "9qeEOsepCqrZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "echo \"=== vCPU disponibles ===\"; nproc\n",
        "echo \"=== Variables de hilos (si la WebUI las heredó) ===\"\n",
        "echo \"OMP_NUM_THREADS=$OMP_NUM_THREADS\"\n",
        "echo \"MKL_NUM_THREADS=$MKL_NUM_THREADS\"\n",
        "echo \"=== Proceso Python más pesado ahora ===\"\n",
        "ps -eo pid,ppid,comm,%cpu,%mem --sort=-%cpu | head -n 10\n"
      ],
      "metadata": {
        "id": "OBskPf1eCuUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Celda A (Python)\n",
        "!py310 -c \"import sys; print('Python', sys.version)\"\n",
        "!py310 -m pip uninstall -y gradio httpx httpcore anyio\n",
        "!py310 -m pip install -q \"gradio==3.14.0\" \"httpx==0.24.1\" \"httpcore==0.17.3\" \"anyio<4\"\n",
        "!py310 - <<'PY'\n",
        "import sys, gradio, httpx, httpcore, anyio\n",
        "print(\"py:\", sys.version.split()[0])\n",
        "print(\"gradio:\", gradio.__version__)\n",
        "print(\"httpx:\", httpx.__version__)\n",
        "print(\"httpcore:\", httpcore.__version__)\n",
        "print(\"anyio:\", getattr(anyio, \"__version__\", \"n/a\"))\n",
        "PY\n"
      ],
      "metadata": {
        "id": "dz8s7XnWYxuY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "pkill -f \"infer-web.py\" 2>/dev/null || true\n",
        "fuser -k 7860/tcp 2>/dev/null || true\n",
        "fuser -k 7861/tcp 2>/dev/null || true\n",
        "echo \"OK: WebUI parada y puertos libres.\"\n"
      ],
      "metadata": {
        "id": "yGnEwSkmY4YF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Celda C (Python): esta celda queda ocupada y aquí verás el enlace\n",
        "%cd /content/Retrieval-based-Voice-Conversion-WebUI\n",
        "!env GRADIO_QUEUE_ENABLED=0 MPLBACKEND=Agg py310 infer-web.py --colab --pycmd py310 --port 7860 --noautoopen --noparallel\n"
      ],
      "metadata": {
        "id": "iEj1N0XGY6nf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "EXP=\"fabian-test\"\n",
        "BASE=\"/content/Retrieval-based-Voice-Conversion-WebUI/logs/$EXP\"\n",
        "\n",
        "echo \"== Carpeta de experimento ==\"\n",
        "ls -ld \"$BASE\" || exit 0\n",
        "\n",
        "echo -e \"\\n== Subcarpetas clave (deben existir y tener archivos) ==\"\n",
        "for d in 0_gt_wavs 1_16k_wavs 2a_f0 2b-f0nsf 3_feature256; do\n",
        "  printf \"%-12s \" \"$d\"\n",
        "  test -d \"$BASE/$d\" && find \"$BASE/$d\" -type f | wc -l || echo \"0\"\n",
        "done\n",
        "\n",
        "echo -e \"\\n== total_fea.npy (features HuBERT) ==\"\n",
        "if [ -f \"$BASE/total_fea.npy\" ]; then\n",
        "  ls -lh \"$BASE/total_fea.npy\"\n",
        "else\n",
        "  echo \"FALTA: $BASE/total_fea.npy\"\n",
        "fi\n",
        "\n",
        "echo -e \"\\n== Índices FAISS ==\"\n",
        "ls -lh \"$BASE\"/trained_IVF*_v1.index 2>/dev/null || echo \"Falta trained_*.index (necesitas Train feature index)\"\n",
        "ls -lh \"$BASE\"/added*.index           2>/dev/null || echo \"Falta added*.index (pulsa Train feature index o créalo con la celda FAISS)\"\n"
      ],
      "metadata": {
        "id": "9sAyL95SZyon"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Guardado al Drive"
      ],
      "metadata": {
        "id": "8Xd9UqSYgY_S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== GUARDAR EN DRIVE (usa esta celda Python con \"!\" delante) ======\n",
        "%cd /content/Retrieval-based-Voice-Conversion-WebUI\n",
        "\n",
        "# 1) crear carpetas destino\n",
        "!mkdir -p \"/content/drive/MyDrive/RVC_models/primer-test/logs\"\n",
        "!mkdir -p \"/content/drive/MyDrive/RVC_models/weights\"\n",
        "\n",
        "# 2) copiar el modelo ligero que usa la UI\n",
        "!cp -u weights/primer-test.pth \"/content/drive/MyDrive/RVC_models/weights/\"\n",
        "\n",
        "# 3) copiar logs del experimento (checkpoints, índices, config, features resumidos)\n",
        "#    si rsync no está, se usa fallback con cp -ru\n",
        "# intento con rsync\n",
        "!rsync -ah --info=stats1 --exclude=\"eval\" logs/primer-test/ \"/content/drive/MyDrive/RVC_models/primer-test/logs/\" || true\n",
        "# fallback (si rsync no existía)\n",
        "!cp -ru logs/primer-test \"/content/drive/MyDrive/RVC_models/\" || true\n",
        "\n",
        "# 4) listar para comprobar\n",
        "!ls -lh \"/content/drive/MyDrive/RVC_models/weights\"\n",
        "!ls -lh \"/content/drive/MyDrive/RVC_models/primer-test/logs\" | sed -n '1,120p'\n"
      ],
      "metadata": {
        "id": "8O_tfRknerGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "set -e\n",
        "cd /content/Retrieval-based-Voice-Conversion-WebUI\n",
        "\n",
        "DST_BASE=\"/content/drive/MyDrive/RVC_models/fabian-test\"\n",
        "mkdir -p \"$DST_BASE/weights\" \"$DST_BASE/logs\"\n",
        "\n",
        "# 1) Modelo ligero que usa la WebUI\n",
        "cp -u \"weights/fabian-test.pth\" \"$DST_BASE/weights/\"\n",
        "\n",
        "# 2) Todo el experimento (configs, índices, features resumidos, ckpts finales…)\n",
        "#    Si existe rsync, úsalo; si no, fallback a cp -ru\n",
        "if command -v rsync >/dev/null 2>&1; then\n",
        "  rsync -ah --info=stats1 --exclude=\"eval\" \"logs/fabian-test/\" \"$DST_BASE/logs/\"\n",
        "else\n",
        "  cp -ru \"logs/fabian-test\" \"$DST_BASE/\"\n",
        "fi\n",
        "\n",
        "echo \"=== GUARDADO EN DRIVE ===\"\n",
        "du -sh \"$DST_BASE\"/weights/* 2>/dev/null || true\n",
        "du -sh \"$DST_BASE\"/logs 2>/dev/null || true\n",
        "ls -lh \"$DST_BASE/weights\" || true\n",
        "ls -lh \"$DST_BASE/logs\" | sed -n '1,120p' || true\n"
      ],
      "metadata": {
        "id": "egsRfBhSk_E8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "BASE=\"/content/drive/MyDrive/RVC_models/fabian-test\"\n",
        "echo \"weights:\"\n",
        "ls -lh \"$BASE/weights\"\n",
        "echo\n",
        "echo \"logs (mira que estén los índices *.index y config.json):\"\n",
        "ls -lh \"$BASE/logs\" | sed -n '1,120p'\n"
      ],
      "metadata": {
        "id": "IXHVk3-xlB3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cargar del Drive una vez se haya iniciado el drive y se haya apuntado al repo"
      ],
      "metadata": {
        "id": "BjzajQ6jgf9D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p weights logs\n",
        "!rm -f weights/primer-test.pth\n",
        "!ln -s \"/content/drive/MyDrive/RVC_models/weights/primer-test.pth\" weights/primer-test.pth\n",
        "\n",
        "!rm -rf logs/primer-test\n",
        "!ln -s \"/content/drive/MyDrive/RVC_models/primer-test/logs\" logs/primer-test\n",
        "\n",
        "# asegúrate de tener alias corto del índice:\n",
        "!bash -lc 'cd logs/primer-test && { test -f added.index || ln -sfn added_IVF*_*_v1.index added.index; }'\n"
      ],
      "metadata": {
        "id": "NcA2ZEaNgepQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/Retrieval-based-Voice-Conversion-WebUI/logs/primer-test\n",
        "# Si existe 'trained_*.index', apúntalo a added.index\n",
        "!ln -sfn trained_IVF742_Flat_nprobe_1_v1.index added.index || true\n",
        "# (alternativa) enlazar el \"added_*\" al nombre corto\n",
        "!test -f added_IVF742_Flat_nprobe_1_v1.index && ln -sfn added_IVF742_Flat_nprobe_1_v1.index added.index || true\n",
        "!ls -lh\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "jD_fWQNnYUuJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CON FABIAN\n",
        "OPCION a"
      ],
      "metadata": {
        "id": "lD8s0K_6losH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cd /content/Retrieval-based-Voice-Conversion-WebUI\n",
        "\n",
        "# 1) estructura local\n",
        "mkdir -p weights logs\n",
        "\n",
        "# 2) enlazar el .pth desde Drive\n",
        "rm -f weights/fabian-test.pth\n",
        "ln -s \"/content/drive/MyDrive/RVC_models/fabian-test/weights/fabian-test.pth\" weights/fabian-test.pth\n",
        "\n",
        "# 3) enlazar los logs (índices, config, etc.)\n",
        "rm -rf logs/fabian-test\n",
        "ln -s \"/content/drive/MyDrive/RVC_models/fabian-test/logs\" logs/fabian-test\n",
        "\n",
        "# 4) alias 'added.index' -> el índice entrenado (si no existe aún)\n",
        "cd logs/fabian-test\n",
        "{ test -f added.index || ln -sfn added_IVF*_*_v1.index added.index; }\n",
        "ls -lh\n"
      ],
      "metadata": {
        "id": "ZhHcmM1QlqR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "OPCION B"
      ],
      "metadata": {
        "id": "HGq4OB_9lw0I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cd /content/Retrieval-based-Voice-Conversion-WebUI\n",
        "\n",
        "# Copia el .pth\n",
        "mkdir -p weights\n",
        "cp -u \"/content/drive/MyDrive/RVC_models/fabian-test/weights/fabian-test.pth\" weights/\n",
        "\n",
        "# Copia los logs\n",
        "mkdir -p logs/fabian-test\n",
        "rsync -ah --info=stats1 \"/content/drive/MyDrive/RVC_models/fabian-test/logs/\" \"logs/fabian-test/\" || cp -ru \"/content/drive/MyDrive/RVC_models/fabian-test/logs/\"* \"logs/fabian-test/\"\n",
        "\n",
        "# Asegura alias del índice\n",
        "cd logs/fabian-test\n",
        "{ test -f added.index || ln -sfn added_IVF*_*_v1.index added.index; }\n",
        "ls -lh\n"
      ],
      "metadata": {
        "id": "YRZGd8hylxxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# De OPUS a WAV INFERENCIA\n"
      ],
      "metadata": {
        "id": "vFA2BoPvhdoQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# OPUS -> WAV (mono, PCM16) con 3 MODOS: no_trim | soft_trim | vad\n",
        "# === CONFIGURA AQUÍ ===\n",
        "SRC  = \"/content/drive/MyDrive/RAVC/Inferencia/fabian/malos\"           # .opus\n",
        "DST  = \"/content/drive/MyDrive/RAVC/Inferencia/fabian/buenos\"  # salida final\n",
        "SR   = 40000                                                 # 48000 si quieres 48k\n",
        "MODE = \"no_trim\"                                             # \"no_trim\" | \"soft_trim\" | \"vad\"\n",
        "\n",
        "import os, glob, shlex, subprocess, sys, math\n",
        "os.makedirs(DST, exist_ok=True)\n",
        "\n",
        "def run(cmd):\n",
        "    return subprocess.run(cmd, shell=True).returncode == 0\n",
        "\n",
        "def ff(cmd_list):\n",
        "    return subprocess.run(cmd_list, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "\n",
        "# ——— helpers VAD (solo si MODE==\"vad\") ———\n",
        "def vad_cut_to_wav(inp, out, sr=SR, aggressiveness=2):\n",
        "    \"\"\"\n",
        "    Recorte por voz con webrtcvad: genera WAV temporal PCM16, trocea por voz y pega.\n",
        "    Más robusto que silenceremove.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        import webrtcvad, wave, contextlib, collections, struct\n",
        "        import tempfile, numpy as np\n",
        "\n",
        "        # 1) decodifica a wav mono/sr fijo\n",
        "        with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as tmpwav:\n",
        "            tmp = tmpwav.name\n",
        "        if not run(f'ffmpeg -nostdin -hide_banner -loglevel error -y -i {shlex.quote(inp)} -ac 1 -ar {sr} -sample_fmt s16 {shlex.quote(tmp)}'):\n",
        "            return False\n",
        "\n",
        "        # 2) lee frames y aplica VAD\n",
        "        vad = webrtcvad.Vad(aggressiveness)\n",
        "        frame_dur_ms = 30\n",
        "        bytes_per_sample = 2\n",
        "        frame_len = int(sr * frame_dur_ms / 1000) * bytes_per_sample\n",
        "        with contextlib.closing(wave.open(tmp, 'rb')) as wf:\n",
        "            assert wf.getnchannels() == 1 and wf.getsampwidth() == 2 and wf.getframerate() == sr\n",
        "            pcm = wf.readframes(wf.getnframes())\n",
        "\n",
        "        # trocear en frames\n",
        "        frames = [pcm[i:i+frame_len] for i in range(0, len(pcm), frame_len)]\n",
        "        voiced = [vad.is_speech(f, sr) if len(f)==frame_len else False for f in frames]\n",
        "\n",
        "        # 3) agrupa regiones con voz\n",
        "        chunks = []\n",
        "        cur = []\n",
        "        for i, (f,isv) in enumerate(zip(frames, voiced)):\n",
        "            if isv:\n",
        "                cur.append(f)\n",
        "            else:\n",
        "                if cur:\n",
        "                    chunks.append(b\"\".join(cur)); cur=[]\n",
        "        if cur:\n",
        "            chunks.append(b\"\".join(cur))\n",
        "\n",
        "        # si no hay voz, exporta 0.5s de silencio para no perder el archivo\n",
        "        if not chunks:\n",
        "            import numpy as np\n",
        "            silence = (np.zeros(int(sr*0.5)).astype(np.int16)).tobytes()\n",
        "            chunks = [silence]\n",
        "\n",
        "        # 4) combina y escribe WAV temporal\n",
        "        payload = b\"\".join(chunks)\n",
        "        with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as tmpcut:\n",
        "            out_cut = tmpcut.name\n",
        "        with wave.open(out_cut, 'wb') as wf:\n",
        "            wf.setnchannels(1); wf.setsampwidth(2); wf.setframerate(sr)\n",
        "            wf.writeframes(payload)\n",
        "\n",
        "        # 5) normaliza y escribe a destino final\n",
        "        af = f\"loudnorm=I=-20:LRA=7:TP=-1.5\"\n",
        "        ok = run(f'ffmpeg -nostdin -hide_banner -loglevel error -y -i {shlex.quote(out_cut)} -af {shlex.quote(af)} -ac 1 -ar {sr} -sample_fmt s16 {shlex.quote(out)}')\n",
        "        try: os.remove(tmp)\n",
        "        except: pass\n",
        "        try: os.remove(out_cut)\n",
        "        except: pass\n",
        "        return ok\n",
        "    except Exception as e:\n",
        "        return False\n",
        "\n",
        "# ——— procesamiento ———\n",
        "patterns = [\"**/*.opus\",\"**/*.OPUS\"]\n",
        "paths = []\n",
        "for pat in patterns:\n",
        "    paths.extend(glob.glob(os.path.join(SRC, pat), recursive=True))\n",
        "print(\"Encontrados .opus:\", len(paths))\n",
        "ok, fail = 0, 0\n",
        "\n",
        "for p in paths:\n",
        "    rel   = os.path.relpath(p, SRC)\n",
        "    base  = os.path.splitext(rel)[0]\n",
        "    out_dir = os.path.join(DST, os.path.dirname(rel)); os.makedirs(out_dir, exist_ok=True)\n",
        "    out = os.path.join(out_dir, base + \".wav\")\n",
        "\n",
        "    if MODE == \"no_trim\":\n",
        "        # SOLO normaliza, no toca duración\n",
        "        af = \"loudnorm=I=-20:LRA=7:TP=-1.5\"\n",
        "        cmd = f'ffmpeg -nostdin -hide_banner -loglevel error -y -i {shlex.quote(p)} -af {shlex.quote(af)} -ac 1 -ar {SR} -sample_fmt s16 {shlex.quote(out)}'\n",
        "        ok += run(cmd); fail += (not ok or 0) and 0\n",
        "\n",
        "    elif MODE == \"soft_trim\":\n",
        "        # Recorte ULTRA conservador (+ normalización)\n",
        "        # Umbral muy bajo (-50 dB) + exige 1.0 s de silencio para cortar\n",
        "        af = (\n",
        "          \"silenceremove=\"\n",
        "          \"start_periods=1:start_silence=1.0:start_threshold=-50dB:\"\n",
        "          \"stop_periods=1:stop_silence=1.0:stop_threshold=-50dB,\"\n",
        "          \"loudnorm=I=-20:LRA=7:TP=-1.5\"\n",
        "        )\n",
        "        cmd = f'ffmpeg -nostdin -hide_banner -loglevel error -y -i {shlex.quote(p)} -af {shlex.quote(af)} -ac 1 -ar {SR} -sample_fmt s16 {shlex.quote(out)}'\n",
        "        ok += run(cmd); fail += (not ok or 0) and 0\n",
        "\n",
        "    elif MODE == \"vad\":\n",
        "        # Recorta por voz con WebRTC VAD + normaliza\n",
        "        if not vad_cut_to_wav(p, out, sr=SR, aggressiveness=2):\n",
        "            fail += 1\n",
        "        else:\n",
        "            ok += 1\n",
        "    else:\n",
        "        print(f\"❌ MODE inválido: {MODE}\"); break\n",
        "\n",
        "print(f\"Terminado. OK={ok} | Fail={len(paths)-ok} | Salida={DST}\")"
      ],
      "metadata": {
        "id": "YLHuE4znxmkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FgJuNeAwx5Y_"
      },
      "outputs": [],
      "source": [
        "# @title #手动将训练后的模型文件备份到谷歌云盘\n",
        "# @markdown #需要自己查看logs文件夹下模型的文件名，手动修改下方命令末尾的文件名\n",
        "\n",
        "# @markdown #模型名\n",
        "MODELNAME = \"lulu\"  # @param {type:\"string\"}\n",
        "# @markdown #模型epoch\n",
        "MODELEPOCH = 9600  # @param {type:\"integer\"}\n",
        "\n",
        "!cp /content/Retrieval-based-Voice-Conversion-WebUI/logs/{MODELNAME}/G_{MODELEPOCH}.pth /content/drive/MyDrive/{MODELNAME}_D_{MODELEPOCH}.pth\n",
        "!cp /content/Retrieval-based-Voice-Conversion-WebUI/logs/{MODELNAME}/D_{MODELEPOCH}.pth /content/drive/MyDrive/{MODELNAME}_G_{MODELEPOCH}.pth\n",
        "!cp /content/Retrieval-based-Voice-Conversion-WebUI/logs/{MODELNAME}/added_*.index /content/drive/MyDrive/\n",
        "!cp /content/Retrieval-based-Voice-Conversion-WebUI/logs/{MODELNAME}/total_*.npy /content/drive/MyDrive/\n",
        "\n",
        "!cp /content/Retrieval-based-Voice-Conversion-WebUI/weights/{MODELNAME}.pth /content/drive/MyDrive/{MODELNAME}{MODELEPOCH}.pth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OVQoLQJXS7WX"
      },
      "outputs": [],
      "source": [
        "# @title 从谷歌云盘恢复pth\n",
        "# @markdown 需要自己查看logs文件夹下模型的文件名，手动修改下方命令末尾的文件名\n",
        "\n",
        "# @markdown 模型名\n",
        "MODELNAME = \"lulu\"  # @param {type:\"string\"}\n",
        "# @markdown 模型epoch\n",
        "MODELEPOCH = 7500  # @param {type:\"integer\"}\n",
        "\n",
        "!mkdir -p /content/Retrieval-based-Voice-Conversion-WebUI/logs/{MODELNAME}\n",
        "\n",
        "!cp /content/drive/MyDrive/{MODELNAME}_D_{MODELEPOCH}.pth /content/Retrieval-based-Voice-Conversion-WebUI/logs/{MODELNAME}/G_{MODELEPOCH}.pth\n",
        "!cp /content/drive/MyDrive/{MODELNAME}_G_{MODELEPOCH}.pth /content/Retrieval-based-Voice-Conversion-WebUI/logs/{MODELNAME}/D_{MODELEPOCH}.pth\n",
        "!cp /content/drive/MyDrive/*.index /content/\n",
        "!cp /content/drive/MyDrive/*.npy /content/\n",
        "!cp /content/drive/MyDrive/{MODELNAME}{MODELEPOCH}.pth /content/Retrieval-based-Voice-Conversion-WebUI/weights/{MODELNAME}.pth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZKAyuKb9J6dz"
      },
      "outputs": [],
      "source": [
        "# @title 手动预处理（不推荐）\n",
        "# @markdown 模型名\n",
        "MODELNAME = \"lulu\"  # @param {type:\"string\"}\n",
        "# @markdown 采样率\n",
        "BITRATE = 48000  # @param {type:\"integer\"}\n",
        "# @markdown 使用的进程数\n",
        "THREADCOUNT = 8  # @param {type:\"integer\"}\n",
        "\n",
        "!python3 trainset_preprocess_pipeline_print.py /content/dataset {BITRATE} {THREADCOUNT} logs/{MODELNAME} True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CrxJqzAUKmPJ"
      },
      "outputs": [],
      "source": [
        "# @title 手动提取特征（不推荐）\n",
        "# @markdown 模型名\n",
        "MODELNAME = \"lulu\"  # @param {type:\"string\"}\n",
        "# @markdown 使用的进程数\n",
        "THREADCOUNT = 8  # @param {type:\"integer\"}\n",
        "# @markdown 音高提取算法\n",
        "ALGO = \"harvest\"  # @param {type:\"string\"}\n",
        "\n",
        "!python3 extract_f0_print.py logs/{MODELNAME} {THREADCOUNT} {ALGO}\n",
        "\n",
        "!python3 extract_feature_print.py cpu 1 0 0 logs/{MODELNAME} True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IMLPLKOaKj58"
      },
      "outputs": [],
      "source": [
        "# @title 手动训练（不推荐）\n",
        "# @markdown 模型名\n",
        "MODELNAME = \"lulu\"  # @param {type:\"string\"}\n",
        "# @markdown 使用的GPU\n",
        "USEGPU = \"0\"  # @param {type:\"string\"}\n",
        "# @markdown 批大小\n",
        "BATCHSIZE = 32  # @param {type:\"integer\"}\n",
        "# @markdown 停止的epoch\n",
        "MODELEPOCH = 3200  # @param {type:\"integer\"}\n",
        "# @markdown 保存epoch间隔\n",
        "EPOCHSAVE = 100  # @param {type:\"integer\"}\n",
        "# @markdown 采样率\n",
        "MODELSAMPLE = \"48k\"  # @param {type:\"string\"}\n",
        "# @markdown 是否缓存训练集\n",
        "CACHEDATA = 1  # @param {type:\"integer\"}\n",
        "# @markdown 是否仅保存最新的ckpt文件\n",
        "ONLYLATEST = 0  # @param {type:\"integer\"}\n",
        "\n",
        "!python3 train_nsf_sim_cache_sid_load_pretrain.py -e lulu -sr {MODELSAMPLE} -f0 1 -bs {BATCHSIZE} -g {USEGPU} -te {MODELEPOCH} -se {EPOCHSAVE} -pg pretrained/f0G{MODELSAMPLE}.pth -pd pretrained/f0D{MODELSAMPLE}.pth -l {ONLYLATEST} -c {CACHEDATA}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "haYA81hySuDl"
      },
      "outputs": [],
      "source": [
        "# @title 删除其它pth，只留选中的（慎点，仔细看代码）\n",
        "# @markdown 模型名\n",
        "MODELNAME = \"lulu\"  # @param {type:\"string\"}\n",
        "# @markdown 选中模型epoch\n",
        "MODELEPOCH = 9600  # @param {type:\"integer\"}\n",
        "\n",
        "!echo \"备份选中的模型。。。\"\n",
        "!cp /content/Retrieval-based-Voice-Conversion-WebUI/logs/{MODELNAME}/G_{MODELEPOCH}.pth /content/{MODELNAME}_D_{MODELEPOCH}.pth\n",
        "!cp /content/Retrieval-based-Voice-Conversion-WebUI/logs/{MODELNAME}/D_{MODELEPOCH}.pth /content/{MODELNAME}_G_{MODELEPOCH}.pth\n",
        "\n",
        "!echo \"正在删除。。。\"\n",
        "!ls /content/Retrieval-based-Voice-Conversion-WebUI/logs/{MODELNAME}\n",
        "!rm /content/Retrieval-based-Voice-Conversion-WebUI/logs/{MODELNAME}/*.pth\n",
        "\n",
        "!echo \"恢复选中的模型。。。\"\n",
        "!mv /content/{MODELNAME}_D_{MODELEPOCH}.pth /content/Retrieval-based-Voice-Conversion-WebUI/logs/{MODELNAME}/G_{MODELEPOCH}.pth\n",
        "!mv /content/{MODELNAME}_G_{MODELEPOCH}.pth /content/Retrieval-based-Voice-Conversion-WebUI/logs/{MODELNAME}/D_{MODELEPOCH}.pth\n",
        "\n",
        "!echo \"删除完成\"\n",
        "!ls /content/Retrieval-based-Voice-Conversion-WebUI/logs/{MODELNAME}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QhSiPTVPoIRh"
      },
      "outputs": [],
      "source": [
        "# @title 清除项目下所有文件，只留选中的模型（慎点，仔细看代码）\n",
        "# @markdown 模型名\n",
        "MODELNAME = \"lulu\"  # @param {type:\"string\"}\n",
        "# @markdown 选中模型epoch\n",
        "MODELEPOCH = 9600  # @param {type:\"integer\"}\n",
        "\n",
        "!echo \"备份选中的模型。。。\"\n",
        "!cp /content/Retrieval-based-Voice-Conversion-WebUI/logs/{MODELNAME}/G_{MODELEPOCH}.pth /content/{MODELNAME}_D_{MODELEPOCH}.pth\n",
        "!cp /content/Retrieval-based-Voice-Conversion-WebUI/logs/{MODELNAME}/D_{MODELEPOCH}.pth /content/{MODELNAME}_G_{MODELEPOCH}.pth\n",
        "\n",
        "!echo \"正在删除。。。\"\n",
        "!ls /content/Retrieval-based-Voice-Conversion-WebUI/logs/{MODELNAME}\n",
        "!rm -rf /content/Retrieval-based-Voice-Conversion-WebUI/logs/{MODELNAME}/*\n",
        "\n",
        "!echo \"恢复选中的模型。。。\"\n",
        "!mv /content/{MODELNAME}_D_{MODELEPOCH}.pth /content/Retrieval-based-Voice-Conversion-WebUI/logs/{MODELNAME}/G_{MODELEPOCH}.pth\n",
        "!mv /content/{MODELNAME}_G_{MODELEPOCH}.pth /content/Retrieval-based-Voice-Conversion-WebUI/logs/{MODELNAME}/D_{MODELEPOCH}.pth\n",
        "\n",
        "!echo \"删除完成\"\n",
        "!ls /content/Retrieval-based-Voice-Conversion-WebUI/logs/{MODELNAME}"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}